{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Type hinting\n",
    "from typing import Tuple\n",
    "# Supress warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets \n",
    "train_data_path = Path(\"./dataset/train.csv\") \n",
    "test_data_path = Path(\"./dataset/test.csv\") \n",
    "train_data = pd.read_csv(train_data_path, encoding='utf-8', index_col='Loan_ID')\n",
    "test_data = pd.read_csv(test_data_path, encoding='utf-8', index_col='Loan_ID')\n",
    "\n",
    "train_data = train_data.drop('Credit_History', axis=1)\n",
    "test_data = test_data.drop('Credit_History', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                   int64\n",
       "Married                  int64\n",
       "Dependents               int64\n",
       "Education                int64\n",
       "Self_Employed            int64\n",
       "ApplicantIncome        float64\n",
       "CoapplicantIncome      float64\n",
       "LoanAmount             float64\n",
       "Loan_Amount_Term       float64\n",
       "Property_Area            int64\n",
       "Total_Income           float64\n",
       "EMI                    float64\n",
       "DTI                    float64\n",
       "Debt_to_Income         float64\n",
       "Income_Per_Capita      float64\n",
       "Income_to_EMI_Ratio    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network_model(input_shape: int) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Create and compile a neural network model.\n",
    "    \"\"\"\n",
    "    KERNEL_REGULARIZER_PARAM: float = 1e-3\n",
    "    model = Sequential([\n",
    "        # Input(shape=(input_shape,)), \n",
    "        Dense(64, activation='relu', \n",
    "              input_shape=(input_shape,), \n",
    "              kernel_regularizer=l2(KERNEL_REGULARIZER_PARAM)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(48, activation='relu', kernel_regularizer=l2(KERNEL_REGULARIZER_PARAM)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(32, activation='relu', kernel_regularizer=l2(KERNEL_REGULARIZER_PARAM)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001, decay=1e-6)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy', \n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.AUC(name='auc')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(X_train: np.ndarray, y_train: pd.Series\n",
    "                        ) -> Tuple[tf.keras.Model, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split the training data, create the neural network model, and train it.\n",
    "    \"\"\"\n",
    "    # Split data into training and validation sets\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = create_neural_network_model(input_shape=X_tr.shape[1])\n",
    "    \n",
    "    # Set up callbacks for early stopping and learning rate reduction\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=50, \n",
    "        restore_best_weights=True,\n",
    "        min_delta=0.001\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.5, \n",
    "        patience=10, \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, X_val, y_val\n",
    "\n",
    "def evaluate_model(model: tf.keras.Model, X_val: np.ndarray, y_val: pd.Series) -> None: \n",
    "    \"\"\"\n",
    "    Evaluates the trained model on the validation set and prints performance metrics.\n",
    "\n",
    "    Parameters:\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        X_val (np.ndarray): Validation features.\n",
    "        y_val (pd.Series): Validation target.\n",
    "    \"\"\"\n",
    "    y_pred_proba = model.predict(X_val).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    print(\"Validation Metrics:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(f\"\\nROC AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_val, y_pred):.4f}\")\n",
    "    return confusion_matrix(y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5311 - auc: 0.4964 - loss: 0.9520 - precision: 0.6928 - recall: 0.5808 - val_accuracy: 0.6734 - val_auc: 0.5077 - val_loss: 0.7308 - val_precision: 0.6807 - val_recall: 0.9778 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6373 - auc: 0.4977 - loss: 0.7711 - precision: 0.6984 - recall: 0.8434 - val_accuracy: 0.6784 - val_auc: 0.5089 - val_loss: 0.7177 - val_precision: 0.6790 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6614 - auc: 0.4978 - loss: 0.7422 - precision: 0.6978 - recall: 0.9093 - val_accuracy: 0.6784 - val_auc: 0.4882 - val_loss: 0.7173 - val_precision: 0.6790 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6616 - auc: 0.5069 - loss: 0.7349 - precision: 0.6840 - recall: 0.9390 - val_accuracy: 0.6793 - val_auc: 0.5097 - val_loss: 0.7106 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6906 - auc: 0.5039 - loss: 0.7097 - precision: 0.7042 - recall: 0.9654 - val_accuracy: 0.6784 - val_auc: 0.4916 - val_loss: 0.7103 - val_precision: 0.6790 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6783 - auc: 0.5094 - loss: 0.7090 - precision: 0.6915 - recall: 0.9670 - val_accuracy: 0.6793 - val_auc: 0.4978 - val_loss: 0.7033 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6897 - auc: 0.5178 - loss: 0.6990 - precision: 0.6957 - recall: 0.9815 - val_accuracy: 0.6793 - val_auc: 0.4861 - val_loss: 0.7006 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6816 - auc: 0.4997 - loss: 0.7004 - precision: 0.6901 - recall: 0.9790 - val_accuracy: 0.6793 - val_auc: 0.4670 - val_loss: 0.6982 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6850 - auc: 0.4825 - loss: 0.6993 - precision: 0.6905 - recall: 0.9870 - val_accuracy: 0.6793 - val_auc: 0.4811 - val_loss: 0.6930 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7009 - auc: 0.5124 - loss: 0.6764 - precision: 0.7047 - recall: 0.9911 - val_accuracy: 0.6793 - val_auc: 0.4938 - val_loss: 0.6886 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6871 - auc: 0.4895 - loss: 0.6895 - precision: 0.6890 - recall: 0.9947 - val_accuracy: 0.6793 - val_auc: 0.4936 - val_loss: 0.6854 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6955 - auc: 0.5079 - loss: 0.6751 - precision: 0.6961 - recall: 0.9980 - val_accuracy: 0.6784 - val_auc: 0.4973 - val_loss: 0.6904 - val_precision: 0.6790 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6926 - auc: 0.5021 - loss: 0.6742 - precision: 0.6943 - recall: 0.9959 - val_accuracy: 0.6784 - val_auc: 0.4925 - val_loss: 0.6960 - val_precision: 0.6790 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6805 - auc: 0.4854 - loss: 0.6828 - precision: 0.6821 - recall: 0.9959 - val_accuracy: 0.6784 - val_auc: 0.4939 - val_loss: 0.6800 - val_precision: 0.6790 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6925 - auc: 0.5139 - loss: 0.6670 - precision: 0.6925 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5007 - val_loss: 0.6736 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6994 - auc: 0.5176 - loss: 0.6600 - precision: 0.6994 - recall: 0.9998 - val_accuracy: 0.6793 - val_auc: 0.5015 - val_loss: 0.6711 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6913 - auc: 0.5021 - loss: 0.6634 - precision: 0.6918 - recall: 0.9990 - val_accuracy: 0.6793 - val_auc: 0.4893 - val_loss: 0.6691 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6887 - auc: 0.5121 - loss: 0.6619 - precision: 0.6886 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4982 - val_loss: 0.6660 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6999 - auc: 0.4975 - loss: 0.6523 - precision: 0.7001 - recall: 0.9995 - val_accuracy: 0.6784 - val_auc: 0.4848 - val_loss: 0.6742 - val_precision: 0.6790 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6881 - auc: 0.5088 - loss: 0.6567 - precision: 0.6883 - recall: 0.9991 - val_accuracy: 0.6793 - val_auc: 0.4895 - val_loss: 0.6606 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7035 - auc: 0.5249 - loss: 0.6400 - precision: 0.7036 - recall: 0.9999 - val_accuracy: 0.6793 - val_auc: 0.4882 - val_loss: 0.6595 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6945 - auc: 0.4954 - loss: 0.6485 - precision: 0.6945 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4911 - val_loss: 0.6566 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7015 - auc: 0.4959 - loss: 0.6392 - precision: 0.7015 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4721 - val_loss: 0.6610 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6842 - auc: 0.4910 - loss: 0.6513 - precision: 0.6842 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4795 - val_loss: 0.6627 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6980 - auc: 0.5095 - loss: 0.6363 - precision: 0.6982 - recall: 0.9997 - val_accuracy: 0.6793 - val_auc: 0.4854 - val_loss: 0.6522 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6901 - auc: 0.5180 - loss: 0.6410 - precision: 0.6901 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4891 - val_loss: 0.6493 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6977 - auc: 0.5115 - loss: 0.6334 - precision: 0.6977 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4958 - val_loss: 0.6481 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7014 - auc: 0.5279 - loss: 0.6277 - precision: 0.7014 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4946 - val_loss: 0.6461 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7028 - auc: 0.5264 - loss: 0.6250 - precision: 0.7028 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4857 - val_loss: 0.6454 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6852 - auc: 0.5035 - loss: 0.6394 - precision: 0.6852 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4959 - val_loss: 0.6430 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7088 - auc: 0.4979 - loss: 0.6199 - precision: 0.7088 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5096 - val_loss: 0.6413 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6993 - auc: 0.5173 - loss: 0.6253 - precision: 0.6993 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5057 - val_loss: 0.6400 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6980 - auc: 0.5127 - loss: 0.6254 - precision: 0.6980 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4971 - val_loss: 0.6429 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7007 - auc: 0.5165 - loss: 0.6219 - precision: 0.7007 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4920 - val_loss: 0.6397 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6900 - auc: 0.5086 - loss: 0.6303 - precision: 0.6900 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4982 - val_loss: 0.6397 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7021 - auc: 0.5035 - loss: 0.6207 - precision: 0.7021 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5121 - val_loss: 0.6367 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7092 - auc: 0.5240 - loss: 0.6122 - precision: 0.7092 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4914 - val_loss: 0.6368 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6879 - auc: 0.4877 - loss: 0.6314 - precision: 0.6879 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4820 - val_loss: 0.6374 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7010 - auc: 0.5090 - loss: 0.6181 - precision: 0.7010 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5139 - val_loss: 0.6356 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6975 - auc: 0.5226 - loss: 0.6200 - precision: 0.6975 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4985 - val_loss: 0.6351 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7050 - auc: 0.5082 - loss: 0.6138 - precision: 0.7050 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5040 - val_loss: 0.6341 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6950 - auc: 0.5220 - loss: 0.6206 - precision: 0.6950 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4954 - val_loss: 0.6350 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6920 - auc: 0.5136 - loss: 0.6239 - precision: 0.6920 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4924 - val_loss: 0.6358 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7057 - auc: 0.5122 - loss: 0.6123 - precision: 0.7057 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4952 - val_loss: 0.6339 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6998 - auc: 0.5161 - loss: 0.6170 - precision: 0.6998 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4978 - val_loss: 0.6345 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7010 - auc: 0.5235 - loss: 0.6148 - precision: 0.7010 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4928 - val_loss: 0.6358 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6974 - auc: 0.5162 - loss: 0.6187 - precision: 0.6974 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4982 - val_loss: 0.6333 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6893 - auc: 0.5069 - loss: 0.6252 - precision: 0.6893 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5005 - val_loss: 0.6345 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6938 - auc: 0.5125 - loss: 0.6209 - precision: 0.6938 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5147 - val_loss: 0.6330 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7039 - auc: 0.5098 - loss: 0.6125 - precision: 0.7039 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5053 - val_loss: 0.6341 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6960 - auc: 0.4952 - loss: 0.6199 - precision: 0.6960 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5036 - val_loss: 0.6338 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - auc: 0.5037 - loss: 0.6198 - precision: 0.6954 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5132 - val_loss: 0.6316 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - auc: 0.5165 - loss: 0.6100 - precision: 0.7062 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5118 - val_loss: 0.6316 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7064 - auc: 0.5060 - loss: 0.6107 - precision: 0.7064 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4947 - val_loss: 0.6321 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - auc: 0.5292 - loss: 0.6170 - precision: 0.6962 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5072 - val_loss: 0.6319 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6975 - auc: 0.5226 - loss: 0.6165 - precision: 0.6975 - recall: 1.0000 - val_accuracy: 0.6767 - val_auc: 0.5098 - val_loss: 0.6330 - val_precision: 0.6785 - val_recall: 0.9963 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6893 - auc: 0.5060 - loss: 0.6242 - precision: 0.6893 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5061 - val_loss: 0.6320 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7078 - auc: 0.5035 - loss: 0.6085 - precision: 0.7078 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5144 - val_loss: 0.6315 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6992 - auc: 0.5215 - loss: 0.6153 - precision: 0.6992 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5089 - val_loss: 0.6328 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6941 - auc: 0.5043 - loss: 0.6202 - precision: 0.6941 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5007 - val_loss: 0.6313 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6964 - auc: 0.5025 - loss: 0.6173 - precision: 0.6964 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5089 - val_loss: 0.6320 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7030 - auc: 0.5433 - loss: 0.6098 - precision: 0.7030 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4935 - val_loss: 0.6317 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7043 - auc: 0.5095 - loss: 0.6110 - precision: 0.7043 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5118 - val_loss: 0.6314 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6888 - auc: 0.5255 - loss: 0.6226 - precision: 0.6888 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5129 - val_loss: 0.6310 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6917 - auc: 0.5154 - loss: 0.6205 - precision: 0.6917 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4995 - val_loss: 0.6309 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6882 - auc: 0.4954 - loss: 0.6239 - precision: 0.6882 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5034 - val_loss: 0.6311 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7087 - auc: 0.5288 - loss: 0.6050 - precision: 0.7087 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5045 - val_loss: 0.6313 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6892 - auc: 0.5140 - loss: 0.6221 - precision: 0.6892 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4988 - val_loss: 0.6316 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7010 - auc: 0.5192 - loss: 0.6126 - precision: 0.7010 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5003 - val_loss: 0.6323 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7149 - auc: 0.5125 - loss: 0.6020 - precision: 0.7149 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4849 - val_loss: 0.6309 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6929 - auc: 0.4997 - loss: 0.6201 - precision: 0.6929 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5027 - val_loss: 0.6319 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7063 - auc: 0.4951 - loss: 0.6093 - precision: 0.7063 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5129 - val_loss: 0.6310 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6964 - auc: 0.5004 - loss: 0.6174 - precision: 0.6964 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4823 - val_loss: 0.6312 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6945 - auc: 0.4945 - loss: 0.6181 - precision: 0.6945 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5058 - val_loss: 0.6304 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - auc: 0.5162 - loss: 0.6127 - precision: 0.7004 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5093 - val_loss: 0.6310 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6969 - auc: 0.5276 - loss: 0.6147 - precision: 0.6969 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5275 - val_loss: 0.6294 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6961 - auc: 0.5008 - loss: 0.6173 - precision: 0.6961 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5063 - val_loss: 0.6305 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6944 - auc: 0.4986 - loss: 0.6184 - precision: 0.6944 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5193 - val_loss: 0.6299 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6924 - auc: 0.4950 - loss: 0.6204 - precision: 0.6924 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5164 - val_loss: 0.6303 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6976 - auc: 0.4794 - loss: 0.6159 - precision: 0.6976 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5202 - val_loss: 0.6299 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6973 - auc: 0.5110 - loss: 0.6151 - precision: 0.6973 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5040 - val_loss: 0.6308 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6953 - auc: 0.4934 - loss: 0.6176 - precision: 0.6953 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4831 - val_loss: 0.6306 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7016 - auc: 0.5155 - loss: 0.6109 - precision: 0.7016 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4892 - val_loss: 0.6305 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6889 - auc: 0.5117 - loss: 0.6219 - precision: 0.6889 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5000 - val_loss: 0.6310 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6974 - auc: 0.4987 - loss: 0.6156 - precision: 0.6974 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5051 - val_loss: 0.6299 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7016 - auc: 0.5161 - loss: 0.6116 - precision: 0.7016 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4984 - val_loss: 0.6299 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6982 - auc: 0.5153 - loss: 0.6144 - precision: 0.6982 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4989 - val_loss: 0.6306 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7016 - auc: 0.5287 - loss: 0.6109 - precision: 0.7016 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5005 - val_loss: 0.6305 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6867 - auc: 0.5475 - loss: 0.6223 - precision: 0.6867 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4918 - val_loss: 0.6311 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6983 - auc: 0.5115 - loss: 0.6139 - precision: 0.6983 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4966 - val_loss: 0.6302 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - auc: 0.5157 - loss: 0.6043 - precision: 0.7098 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5003 - val_loss: 0.6299 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - auc: 0.5377 - loss: 0.6166 - precision: 0.6937 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5102 - val_loss: 0.6298 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7020 - auc: 0.5274 - loss: 0.6101 - precision: 0.7020 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5067 - val_loss: 0.6295 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6864 - auc: 0.5207 - loss: 0.6230 - precision: 0.6864 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5172 - val_loss: 0.6294 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6825 - auc: 0.5112 - loss: 0.6264 - precision: 0.6825 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5153 - val_loss: 0.6290 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6947 - auc: 0.4991 - loss: 0.6171 - precision: 0.6947 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5035 - val_loss: 0.6294 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6983 - auc: 0.5297 - loss: 0.6131 - precision: 0.6983 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5031 - val_loss: 0.6298 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6901 - auc: 0.5383 - loss: 0.6189 - precision: 0.6901 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4921 - val_loss: 0.6303 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - auc: 0.5211 - loss: 0.6114 - precision: 0.7004 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4866 - val_loss: 0.6304 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6905 - auc: 0.5318 - loss: 0.6191 - precision: 0.6905 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5244 - val_loss: 0.6289 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7147 - auc: 0.5207 - loss: 0.5992 - precision: 0.7147 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5138 - val_loss: 0.6287 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6940 - auc: 0.5455 - loss: 0.6153 - precision: 0.6940 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5115 - val_loss: 0.6297 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7034 - auc: 0.4924 - loss: 0.6102 - precision: 0.7034 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5130 - val_loss: 0.6291 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7000 - auc: 0.5407 - loss: 0.6101 - precision: 0.7000 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5173 - val_loss: 0.6292 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7022 - auc: 0.5068 - loss: 0.6107 - precision: 0.7022 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5118 - val_loss: 0.6296 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7033 - auc: 0.5265 - loss: 0.6087 - precision: 0.7033 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5136 - val_loss: 0.6300 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6904 - auc: 0.5302 - loss: 0.6190 - precision: 0.6904 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4991 - val_loss: 0.6300 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6880 - auc: 0.5258 - loss: 0.6216 - precision: 0.6880 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5033 - val_loss: 0.6300 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6987 - auc: 0.5235 - loss: 0.6118 - precision: 0.6987 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4923 - val_loss: 0.6304 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7044 - auc: 0.5108 - loss: 0.6084 - precision: 0.7044 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.4994 - val_loss: 0.6300 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6913 - auc: 0.5433 - loss: 0.6175 - precision: 0.6913 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5189 - val_loss: 0.6289 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6970 - auc: 0.5272 - loss: 0.6136 - precision: 0.6970 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5152 - val_loss: 0.6294 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7012 - auc: 0.5237 - loss: 0.6102 - precision: 0.7012 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5085 - val_loss: 0.6304 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7013 - auc: 0.5072 - loss: 0.6115 - precision: 0.7013 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5063 - val_loss: 0.6299 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6803 - auc: 0.5357 - loss: 0.6261 - precision: 0.6803 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5140 - val_loss: 0.6295 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6883 - auc: 0.5282 - loss: 0.6205 - precision: 0.6883 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5067 - val_loss: 0.6300 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7013 - auc: 0.5353 - loss: 0.6095 - precision: 0.7013 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5086 - val_loss: 0.6298 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7013 - auc: 0.5430 - loss: 0.6090 - precision: 0.7013 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5046 - val_loss: 0.6303 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6928 - auc: 0.5401 - loss: 0.6165 - precision: 0.6928 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5019 - val_loss: 0.6304 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - auc: 0.5417 - loss: 0.6186 - precision: 0.6895 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5069 - val_loss: 0.6297 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6971 - auc: 0.5261 - loss: 0.6138 - precision: 0.6971 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5059 - val_loss: 0.6302 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - auc: 0.5321 - loss: 0.6137 - precision: 0.6963 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5106 - val_loss: 0.6299 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - auc: 0.5529 - loss: 0.6142 - precision: 0.6937 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5147 - val_loss: 0.6298 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6989 - auc: 0.5240 - loss: 0.6122 - precision: 0.6989 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5109 - val_loss: 0.6302 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - auc: 0.5399 - loss: 0.6098 - precision: 0.7004 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5115 - val_loss: 0.6298 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7104 - auc: 0.5377 - loss: 0.6013 - precision: 0.7104 - recall: 1.0000 - val_accuracy: 0.6793 - val_auc: 0.5118 - val_loss: 0.6294 - val_precision: 0.6793 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network and obtain validation data\n",
    "with tf.device('CPU'):  # Tensorflow metal support not matured enough ig\n",
    "    model, X_val, y_val = train_neural_network(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Validation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       382\n",
      "           1       0.68      1.00      0.81       809\n",
      "\n",
      "    accuracy                           0.68      1191\n",
      "   macro avg       0.34      0.50      0.40      1191\n",
      "weighted avg       0.46      0.68      0.55      1191\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 382]\n",
      " [  0 809]]\n",
      "\n",
      "ROC AUC Score: 0.5286\n",
      "F1 Score: 0.8090\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False Positive</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True Positive</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Component  Value\n",
       "0   True negative      0\n",
       "1  False Positive    382\n",
       "2  False negative      0\n",
       "3   True Positive    809"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = evaluate_model(model, X_val, y_val)\n",
    "\n",
    "cm_ravel_cpms = ['True negative', 'False Positive', 'False negative', 'True Positive'] \n",
    "\n",
    "print()\n",
    "pd.DataFrame({\n",
    "    'Component': cm_ravel_cpms, \n",
    "    'Value' : cm.ravel()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Loan_Approval_Status\n",
      "N    100.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Loan_ID': X_test.index,\n",
    "    'Loan_Approval_Status': ['Y' if pred == 1 else 'N' for pred in test_predictions],\n",
    "})\n",
    "\n",
    "print(predictions_df['Loan_Approval_Status'].value_counts(normalize=True) * 100)\n",
    "\n",
    "predictions_pie = predictions_df['Loan_Approval_Status'].value_counts()\\\n",
    "    .plot(kind='pie', title='Model predictions on test set', ylabel=\"Approved Loan count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model=model, fp=\"/Users/samarth/Programming/Loaner/model/nn.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loaner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
