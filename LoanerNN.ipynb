{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "from utils import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Type hinting\n",
    "from typing import Tuple\n",
    "# Supress arnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets \n",
    "train_data_path = Path(\"./dataset/train_extended.csv\") \n",
    "test_data_path = Path(\"./dataset/test.csv\") \n",
    "train_data = pd.read_csv(train_data_path, encoding='utf-8', index_col='Loan_ID')\n",
    "test_data = pd.read_csv(test_data_path, encoding='utf-8', index_col='Loan_ID')\n",
    "\n",
    "train_data = train_data.drop('Credit_History', axis=1)\n",
    "test_data = test_data.drop('Credit_History', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = get_train_test_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                   int64\n",
       "Married                  int64\n",
       "Dependents               int64\n",
       "Education                int64\n",
       "Self_Employed            int64\n",
       "ApplicantIncome        float64\n",
       "CoapplicantIncome      float64\n",
       "LoanAmount             float64\n",
       "Loan_Amount_Term       float64\n",
       "Property_Area            int64\n",
       "Total_Income           float64\n",
       "EMI                    float64\n",
       "DTI                    float64\n",
       "Debt_to_Income         float64\n",
       "Income_Per_Capita      float64\n",
       "Income_to_EMI_Ratio    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network_model(input_shape: int) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Create and compile a neural network model.\n",
    "    \"\"\"\n",
    "    KERNEL_REGULARIZER_PARAM: float = 1e-3\n",
    "    model = Sequential([\n",
    "        # Input(shape=(input_shape,)), \n",
    "        Dense(64, activation='relu', \n",
    "              input_shape=(input_shape,), \n",
    "              kernel_regularizer=l2(KERNEL_REGULARIZER_PARAM)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(48, activation='relu', kernel_regularizer=l2(KERNEL_REGULARIZER_PARAM)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(32, activation='relu', kernel_regularizer=l2(KERNEL_REGULARIZER_PARAM)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001, decay=1e-6)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy', \n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.AUC(name='auc')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(X_train: np.ndarray, y_train: pd.Series\n",
    "                        ) -> Tuple[tf.keras.Model, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split the training data, create the neural network model, and train it.\n",
    "    \"\"\"\n",
    "    # Split data into training and validation sets\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = create_neural_network_model(input_shape=X_tr.shape[1])\n",
    "    \n",
    "    # Set up callbacks for early stopping and learning rate reduction\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=50, \n",
    "        restore_best_weights=True,\n",
    "        min_delta=0.001\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.5, \n",
    "        patience=10, \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_tr, y_tr,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, X_val, y_val\n",
    "\n",
    "def evaluate_model(model: tf.keras.Model, X_val: np.ndarray, y_val: pd.Series) -> None: \n",
    "    \"\"\"\n",
    "    Evaluates the trained model on the validation set and prints performance metrics.\n",
    "\n",
    "    Parameters:\n",
    "        model (tf.keras.Model): Trained model.\n",
    "        X_val (np.ndarray): Validation features.\n",
    "        y_val (pd.Series): Validation target.\n",
    "    \"\"\"\n",
    "    y_pred_proba = model.predict(X_val).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    print(\"Validation Metrics:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(f\"\\nROC AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_val, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5315 - auc: 0.5112 - loss: 0.9194 - precision_8: 0.7046 - recall_8: 0.5656 - val_accuracy: 0.6825 - val_auc: 0.4895 - val_loss: 0.7382 - val_precision_8: 0.6961 - val_recall_8: 0.9640 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6496 - auc: 0.5199 - loss: 0.7501 - precision_8: 0.7095 - recall_8: 0.8574 - val_accuracy: 0.6950 - val_auc: 0.4896 - val_loss: 0.7160 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6662 - auc: 0.5188 - loss: 0.7349 - precision_8: 0.6982 - recall_8: 0.9232 - val_accuracy: 0.6950 - val_auc: 0.4854 - val_loss: 0.7065 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6757 - auc: 0.4915 - loss: 0.7276 - precision_8: 0.6968 - recall_8: 0.9514 - val_accuracy: 0.6933 - val_auc: 0.4907 - val_loss: 0.6971 - val_precision_8: 0.6945 - val_recall_8: 0.9976 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6741 - auc: 0.4914 - loss: 0.7297 - precision_8: 0.6894 - recall_8: 0.9607 - val_accuracy: 0.6950 - val_auc: 0.4702 - val_loss: 0.6976 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6851 - auc: 0.4962 - loss: 0.7132 - precision_8: 0.6954 - recall_8: 0.9741 - val_accuracy: 0.6950 - val_auc: 0.4801 - val_loss: 0.6893 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6863 - auc: 0.5132 - loss: 0.6994 - precision_8: 0.6931 - recall_8: 0.9824 - val_accuracy: 0.6950 - val_auc: 0.4980 - val_loss: 0.6845 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6866 - auc: 0.5073 - loss: 0.6976 - precision_8: 0.6904 - recall_8: 0.9887 - val_accuracy: 0.6950 - val_auc: 0.4946 - val_loss: 0.6849 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6899 - auc: 0.5089 - loss: 0.6880 - precision_8: 0.6926 - recall_8: 0.9923 - val_accuracy: 0.6950 - val_auc: 0.5070 - val_loss: 0.6779 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6826 - auc: 0.5056 - loss: 0.6904 - precision_8: 0.6852 - recall_8: 0.9926 - val_accuracy: 0.6950 - val_auc: 0.4878 - val_loss: 0.6763 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - auc: 0.5031 - loss: 0.6754 - precision_8: 0.7002 - recall_8: 0.9917 - val_accuracy: 0.6950 - val_auc: 0.5049 - val_loss: 0.6725 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6917 - auc: 0.4995 - loss: 0.6772 - precision_8: 0.6933 - recall_8: 0.9962 - val_accuracy: 0.6950 - val_auc: 0.5000 - val_loss: 0.6683 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6766 - auc: 0.5115 - loss: 0.6851 - precision_8: 0.6772 - recall_8: 0.9980 - val_accuracy: 0.6950 - val_auc: 0.5266 - val_loss: 0.6640 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6964 - auc: 0.5093 - loss: 0.6647 - precision_8: 0.6980 - recall_8: 0.9958 - val_accuracy: 0.6950 - val_auc: 0.5103 - val_loss: 0.6625 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - auc: 0.5069 - loss: 0.6616 - precision_8: 0.6962 - recall_8: 0.9988 - val_accuracy: 0.6950 - val_auc: 0.5035 - val_loss: 0.6583 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6939 - auc: 0.5167 - loss: 0.6584 - precision_8: 0.6949 - recall_8: 0.9972 - val_accuracy: 0.6950 - val_auc: 0.4985 - val_loss: 0.6554 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6996 - auc: 0.5037 - loss: 0.6529 - precision_8: 0.7003 - recall_8: 0.9979 - val_accuracy: 0.6950 - val_auc: 0.5159 - val_loss: 0.6535 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6865 - auc: 0.5112 - loss: 0.6613 - precision_8: 0.6872 - recall_8: 0.9986 - val_accuracy: 0.6950 - val_auc: 0.4970 - val_loss: 0.6500 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6969 - auc: 0.5083 - loss: 0.6487 - precision_8: 0.6976 - recall_8: 0.9986 - val_accuracy: 0.6950 - val_auc: 0.5011 - val_loss: 0.6463 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6921 - auc: 0.5331 - loss: 0.6454 - precision_8: 0.6931 - recall_8: 0.9981 - val_accuracy: 0.6950 - val_auc: 0.4948 - val_loss: 0.6447 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6906 - auc: 0.5069 - loss: 0.6485 - precision_8: 0.6910 - recall_8: 0.9989 - val_accuracy: 0.6950 - val_auc: 0.5011 - val_loss: 0.6427 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7062 - auc: 0.5158 - loss: 0.6322 - precision_8: 0.7063 - recall_8: 0.9997 - val_accuracy: 0.6950 - val_auc: 0.5149 - val_loss: 0.6425 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6914 - auc: 0.5191 - loss: 0.6442 - precision_8: 0.6915 - recall_8: 0.9996 - val_accuracy: 0.6950 - val_auc: 0.5127 - val_loss: 0.6379 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - auc: 0.5283 - loss: 0.6343 - precision_8: 0.6964 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5001 - val_loss: 0.6363 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7039 - auc: 0.5212 - loss: 0.6293 - precision_8: 0.7039 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5017 - val_loss: 0.6339 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - auc: 0.5268 - loss: 0.6338 - precision_8: 0.6948 - recall_8: 0.9997 - val_accuracy: 0.6950 - val_auc: 0.5017 - val_loss: 0.6339 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6885 - auc: 0.5191 - loss: 0.6382 - precision_8: 0.6885 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5026 - val_loss: 0.6309 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6924 - auc: 0.5143 - loss: 0.6337 - precision_8: 0.6924 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4843 - val_loss: 0.6321 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6863 - auc: 0.5195 - loss: 0.6369 - precision_8: 0.6863 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5164 - val_loss: 0.6277 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6952 - auc: 0.5105 - loss: 0.6281 - precision_8: 0.6952 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4994 - val_loss: 0.6306 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6939 - auc: 0.4914 - loss: 0.6317 - precision_8: 0.6939 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4932 - val_loss: 0.6277 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6885 - auc: 0.5145 - loss: 0.6314 - precision_8: 0.6885 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4997 - val_loss: 0.6272 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6810 - auc: 0.5202 - loss: 0.6371 - precision_8: 0.6810 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4968 - val_loss: 0.6272 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7088 - auc: 0.5370 - loss: 0.6119 - precision_8: 0.7088 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5099 - val_loss: 0.6255 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6859 - auc: 0.5221 - loss: 0.6323 - precision_8: 0.6859 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5031 - val_loss: 0.6242 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6902 - auc: 0.4955 - loss: 0.6288 - precision_8: 0.6902 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5093 - val_loss: 0.6231 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6976 - auc: 0.4973 - loss: 0.6226 - precision_8: 0.6979 - recall_8: 0.9996 - val_accuracy: 0.6950 - val_auc: 0.5022 - val_loss: 0.6227 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6879 - auc: 0.5036 - loss: 0.6290 - precision_8: 0.6879 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4960 - val_loss: 0.6248 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6946 - auc: 0.5188 - loss: 0.6223 - precision_8: 0.6946 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4926 - val_loss: 0.6233 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7048 - auc: 0.5457 - loss: 0.6111 - precision_8: 0.7048 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4900 - val_loss: 0.6231 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6964 - auc: 0.5338 - loss: 0.6184 - precision_8: 0.6964 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4935 - val_loss: 0.6216 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6897 - auc: 0.5117 - loss: 0.6254 - precision_8: 0.6897 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4941 - val_loss: 0.6240 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7022 - auc: 0.5510 - loss: 0.6126 - precision_8: 0.7022 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4943 - val_loss: 0.6215 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6921 - auc: 0.4803 - loss: 0.6254 - precision_8: 0.6921 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4992 - val_loss: 0.6211 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6931 - auc: 0.5203 - loss: 0.6215 - precision_8: 0.6931 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5139 - val_loss: 0.6201 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6936 - auc: 0.5287 - loss: 0.6200 - precision_8: 0.6936 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5090 - val_loss: 0.6202 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6962 - auc: 0.5186 - loss: 0.6184 - precision_8: 0.6962 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5122 - val_loss: 0.6200 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6919 - auc: 0.5103 - loss: 0.6231 - precision_8: 0.6919 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4936 - val_loss: 0.6209 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6872 - auc: 0.5123 - loss: 0.6266 - precision_8: 0.6872 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4903 - val_loss: 0.6204 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6958 - auc: 0.5248 - loss: 0.6185 - precision_8: 0.6958 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5046 - val_loss: 0.6208 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6942 - auc: 0.5065 - loss: 0.6203 - precision_8: 0.6942 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4934 - val_loss: 0.6209 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6921 - auc: 0.5387 - loss: 0.6203 - precision_8: 0.6921 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4954 - val_loss: 0.6208 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6926 - auc: 0.5171 - loss: 0.6218 - precision_8: 0.6926 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4854 - val_loss: 0.6197 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6908 - auc: 0.5062 - loss: 0.6228 - precision_8: 0.6908 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5098 - val_loss: 0.6192 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6896 - auc: 0.4994 - loss: 0.6237 - precision_8: 0.6896 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4800 - val_loss: 0.6200 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7011 - auc: 0.5198 - loss: 0.6133 - precision_8: 0.7011 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4771 - val_loss: 0.6213 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6955 - auc: 0.5379 - loss: 0.6150 - precision_8: 0.6955 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4696 - val_loss: 0.6197 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6894 - auc: 0.5127 - loss: 0.6224 - precision_8: 0.6894 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5053 - val_loss: 0.6196 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6957 - auc: 0.5061 - loss: 0.6176 - precision_8: 0.6957 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4999 - val_loss: 0.6193 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6902 - auc: 0.4967 - loss: 0.6232 - precision_8: 0.6902 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5040 - val_loss: 0.6201 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6897 - auc: 0.5184 - loss: 0.6224 - precision_8: 0.6897 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4827 - val_loss: 0.6221 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6995 - auc: 0.5296 - loss: 0.6138 - precision_8: 0.6995 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4861 - val_loss: 0.6206 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7018 - auc: 0.5150 - loss: 0.6125 - precision_8: 0.7018 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5032 - val_loss: 0.6198 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6909 - auc: 0.5248 - loss: 0.6197 - precision_8: 0.6909 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5088 - val_loss: 0.6188 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6850 - auc: 0.5237 - loss: 0.6258 - precision_8: 0.6850 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5133 - val_loss: 0.6190 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6798 - auc: 0.5016 - loss: 0.6311 - precision_8: 0.6798 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4892 - val_loss: 0.6191 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6898 - auc: 0.5307 - loss: 0.6206 - precision_8: 0.6898 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5096 - val_loss: 0.6183 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6927 - auc: 0.5262 - loss: 0.6192 - precision_8: 0.6927 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4991 - val_loss: 0.6184 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6923 - auc: 0.5131 - loss: 0.6200 - precision_8: 0.6923 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4909 - val_loss: 0.6188 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6942 - auc: 0.5057 - loss: 0.6183 - precision_8: 0.6942 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4880 - val_loss: 0.6198 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6950 - auc: 0.5157 - loss: 0.6170 - precision_8: 0.6950 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4799 - val_loss: 0.6186 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6856 - auc: 0.4993 - loss: 0.6253 - precision_8: 0.6856 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4789 - val_loss: 0.6186 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6913 - auc: 0.5057 - loss: 0.6204 - precision_8: 0.6913 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4856 - val_loss: 0.6199 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7056 - auc: 0.5267 - loss: 0.6075 - precision_8: 0.7056 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4966 - val_loss: 0.6188 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6935 - auc: 0.5299 - loss: 0.6178 - precision_8: 0.6935 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4810 - val_loss: 0.6187 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6930 - auc: 0.5274 - loss: 0.6184 - precision_8: 0.6930 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5138 - val_loss: 0.6178 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6888 - auc: 0.4991 - loss: 0.6225 - precision_8: 0.6888 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5024 - val_loss: 0.6180 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6895 - auc: 0.5049 - loss: 0.6211 - precision_8: 0.6895 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4930 - val_loss: 0.6180 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6967 - auc: 0.5260 - loss: 0.6150 - precision_8: 0.6967 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4891 - val_loss: 0.6183 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6903 - auc: 0.5046 - loss: 0.6211 - precision_8: 0.6903 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4916 - val_loss: 0.6179 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6893 - auc: 0.5209 - loss: 0.6208 - precision_8: 0.6893 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4872 - val_loss: 0.6181 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6967 - auc: 0.5259 - loss: 0.6148 - precision_8: 0.6967 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4831 - val_loss: 0.6191 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6891 - auc: 0.5021 - loss: 0.6229 - precision_8: 0.6891 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5060 - val_loss: 0.6191 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6972 - auc: 0.5143 - loss: 0.6148 - precision_8: 0.6972 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5019 - val_loss: 0.6172 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7046 - auc: 0.5070 - loss: 0.6091 - precision_8: 0.7046 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4859 - val_loss: 0.6176 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6851 - auc: 0.5162 - loss: 0.6244 - precision_8: 0.6851 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4770 - val_loss: 0.6189 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6835 - auc: 0.5268 - loss: 0.6260 - precision_8: 0.6835 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4911 - val_loss: 0.6180 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6916 - auc: 0.4956 - loss: 0.6207 - precision_8: 0.6916 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4914 - val_loss: 0.6175 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7018 - auc: 0.5035 - loss: 0.6115 - precision_8: 0.7018 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4935 - val_loss: 0.6178 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 90/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7071 - auc: 0.5155 - loss: 0.6066 - precision_8: 0.7071 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4807 - val_loss: 0.6185 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 91/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6916 - auc: 0.5109 - loss: 0.6196 - precision_8: 0.6916 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4994 - val_loss: 0.6171 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 92/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6954 - auc: 0.5241 - loss: 0.6148 - precision_8: 0.6954 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5062 - val_loss: 0.6170 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 93/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6866 - auc: 0.5194 - loss: 0.6227 - precision_8: 0.6866 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5097 - val_loss: 0.6174 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 94/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6931 - auc: 0.5134 - loss: 0.6180 - precision_8: 0.6931 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4777 - val_loss: 0.6175 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 95/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6927 - auc: 0.5193 - loss: 0.6183 - precision_8: 0.6927 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5074 - val_loss: 0.6167 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 96/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6938 - auc: 0.5219 - loss: 0.6173 - precision_8: 0.6938 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5117 - val_loss: 0.6170 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 97/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6980 - auc: 0.4935 - loss: 0.6149 - precision_8: 0.6980 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5171 - val_loss: 0.6169 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 98/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7006 - auc: 0.5133 - loss: 0.6111 - precision_8: 0.7006 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4994 - val_loss: 0.6182 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 99/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6921 - auc: 0.4962 - loss: 0.6186 - precision_8: 0.6921 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4845 - val_loss: 0.6170 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 100/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6868 - auc: 0.5312 - loss: 0.6219 - precision_8: 0.6868 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4952 - val_loss: 0.6183 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 101/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6772 - auc: 0.5105 - loss: 0.6307 - precision_8: 0.6772 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5148 - val_loss: 0.6175 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6892 - auc: 0.5337 - loss: 0.6197 - precision_8: 0.6892 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5027 - val_loss: 0.6177 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 103/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6841 - auc: 0.5078 - loss: 0.6251 - precision_8: 0.6841 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4984 - val_loss: 0.6173 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 104/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6980 - auc: 0.5211 - loss: 0.6134 - precision_8: 0.6980 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4913 - val_loss: 0.6187 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 105/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6872 - auc: 0.5216 - loss: 0.6213 - precision_8: 0.6872 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4812 - val_loss: 0.6170 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 106/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6915 - auc: 0.5226 - loss: 0.6183 - precision_8: 0.6915 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4861 - val_loss: 0.6168 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6940 - auc: 0.5138 - loss: 0.6162 - precision_8: 0.6940 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4911 - val_loss: 0.6168 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7004 - auc: 0.4991 - loss: 0.6119 - precision_8: 0.7004 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4872 - val_loss: 0.6170 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6892 - auc: 0.5331 - loss: 0.6194 - precision_8: 0.6892 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4903 - val_loss: 0.6165 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7009 - auc: 0.4975 - loss: 0.6124 - precision_8: 0.7009 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5059 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6902 - auc: 0.5379 - loss: 0.6181 - precision_8: 0.6902 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4940 - val_loss: 0.6164 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6860 - auc: 0.5081 - loss: 0.6226 - precision_8: 0.6860 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.5009 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6913 - auc: 0.5090 - loss: 0.6185 - precision_8: 0.6913 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4995 - val_loss: 0.6163 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6920 - auc: 0.5091 - loss: 0.6192 - precision_8: 0.6920 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4941 - val_loss: 0.6165 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6962 - auc: 0.5045 - loss: 0.6148 - precision_8: 0.6962 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4806 - val_loss: 0.6164 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6942 - auc: 0.5136 - loss: 0.6158 - precision_8: 0.6942 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4873 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6908 - auc: 0.5175 - loss: 0.6188 - precision_8: 0.6908 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4909 - val_loss: 0.6169 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6936 - auc: 0.5222 - loss: 0.6169 - precision_8: 0.6936 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4794 - val_loss: 0.6172 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6925 - auc: 0.5174 - loss: 0.6167 - precision_8: 0.6925 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4777 - val_loss: 0.6170 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7011 - auc: 0.5177 - loss: 0.6110 - precision_8: 0.7011 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4849 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6978 - auc: 0.5212 - loss: 0.6129 - precision_8: 0.6978 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4796 - val_loss: 0.6173 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6855 - auc: 0.4953 - loss: 0.6236 - precision_8: 0.6855 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4940 - val_loss: 0.6169 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6931 - auc: 0.5017 - loss: 0.6183 - precision_8: 0.6931 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4825 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7070 - auc: 0.5172 - loss: 0.6047 - precision_8: 0.7070 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4946 - val_loss: 0.6167 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - auc: 0.5066 - loss: 0.6166 - precision_8: 0.6933 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4902 - val_loss: 0.6167 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6898 - auc: 0.5271 - loss: 0.6182 - precision_8: 0.6898 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4854 - val_loss: 0.6164 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7027 - auc: 0.5295 - loss: 0.6076 - precision_8: 0.7027 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4920 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6960 - auc: 0.5137 - loss: 0.6143 - precision_8: 0.6960 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4808 - val_loss: 0.6168 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7012 - auc: 0.5298 - loss: 0.6093 - precision_8: 0.7012 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4815 - val_loss: 0.6170 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6947 - auc: 0.5420 - loss: 0.6142 - precision_8: 0.6947 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4951 - val_loss: 0.6165 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6889 - auc: 0.5129 - loss: 0.6201 - precision_8: 0.6889 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4874 - val_loss: 0.6165 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6915 - auc: 0.5151 - loss: 0.6179 - precision_8: 0.6915 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4812 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7003 - auc: 0.5299 - loss: 0.6099 - precision_8: 0.7003 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4793 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7037 - auc: 0.5143 - loss: 0.6089 - precision_8: 0.7037 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4752 - val_loss: 0.6166 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6851 - auc: 0.5471 - loss: 0.6215 - precision_8: 0.6851 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4854 - val_loss: 0.6165 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6914 - auc: 0.5248 - loss: 0.6181 - precision_8: 0.6914 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4684 - val_loss: 0.6168 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6921 - auc: 0.5341 - loss: 0.6167 - precision_8: 0.6921 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4797 - val_loss: 0.6165 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6903 - auc: 0.5164 - loss: 0.6196 - precision_8: 0.6903 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4864 - val_loss: 0.6169 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6846 - auc: 0.5391 - loss: 0.6222 - precision_8: 0.6846 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4803 - val_loss: 0.6165 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7055 - auc: 0.5346 - loss: 0.6054 - precision_8: 0.7055 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4930 - val_loss: 0.6164 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6992 - auc: 0.5333 - loss: 0.6107 - precision_8: 0.6992 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4892 - val_loss: 0.6162 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7034 - auc: 0.5426 - loss: 0.6075 - precision_8: 0.7034 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4870 - val_loss: 0.6163 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6996 - auc: 0.5386 - loss: 0.6103 - precision_8: 0.6996 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4868 - val_loss: 0.6163 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6845 - auc: 0.5394 - loss: 0.6224 - precision_8: 0.6845 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4873 - val_loss: 0.6164 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6891 - auc: 0.5111 - loss: 0.6202 - precision_8: 0.6891 - recall_8: 1.0000 - val_accuracy: 0.6950 - val_auc: 0.4878 - val_loss: 0.6164 - val_precision_8: 0.6950 - val_recall_8: 1.0000 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network and obtain validation data\n",
    "model, X_val, y_val = train_neural_network(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Validation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       366\n",
      "           1       0.69      1.00      0.82       834\n",
      "\n",
      "    accuracy                           0.69      1200\n",
      "   macro avg       0.35      0.50      0.41      1200\n",
      "weighted avg       0.48      0.69      0.57      1200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 366]\n",
      " [  0 834]]\n",
      "\n",
      "ROC AUC Score: 0.4955\n",
      "F1 Score: 0.8201\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step\n",
      "Loan_Approval_Status\n",
      "N    100.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test predicitons with test dataset \n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Loan_ID': test_data.index,\n",
    "    'Loan_Approval_Status': ['Y' if pred == 1 else 'N' for pred in test_predictions],\n",
    "})\n",
    "\n",
    "print(predictions_df['Loan_Approval_Status'].value_counts(normalize=True) * 100)\n",
    "\n",
    "predictions_pie = predictions_df['Loan_Approval_Status'].value_counts()\\\n",
    "    .plot(kind='pie', title='Model predictions on test set', ylabel=\"Approved Loan count\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
